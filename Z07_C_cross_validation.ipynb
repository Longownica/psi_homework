{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_wJQ0OQhfsux"
      },
      "source": [
        "# Regresja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LPf_769efsuz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h_HmfmHfsu2"
      },
      "source": [
        "Rozważmy zbiór Boston"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tdd1LGT7fsu3",
        "outputId": "ab8d1357-1b22-4037-b02b-a5eab8e9c78e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "boston = datasets.load_boston()\n",
        "# print description\n",
        "# print(boston.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "tMcBbfiSfsu4"
      },
      "outputs": [],
      "source": [
        "# get the data\n",
        "boston_X = boston.data\n",
        "boston_Y = boston.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvklVt2kfsu6"
      },
      "source": [
        "Podzielmy zbiór na część testową i treningową ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "g7Ie1I05fsu7"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "boston_X_train = boston_X[:-50]\n",
        "boston_X_test = boston_X[-50:]\n",
        " \n",
        "# Split the targets into training/testing sets\n",
        "boston_y_train = boston_Y[:-50]\n",
        "boston_y_test = boston_Y[-50:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "uHE372sofsu7"
      },
      "outputs": [],
      "source": [
        "X=boston_X_train\n",
        "y=boston_y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmCoBWOyfsu9"
      },
      "source": [
        "# Zadanie\n",
        "Znajdż najleprzy model dzieląc na zbiór testowy i terningowy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "9R9pYu6sfsu_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import model_selection\n",
        "\n",
        "seed=123\n",
        "kfold = model_selection.KFold(n_splits=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_gt2Ufu0fsvA",
        "outputId": "ddf63658-ae3c-468a-b6e8-99928f9b8872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.027e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.618e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.317e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.481e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.901e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.817e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.349e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.674e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.161e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.575e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.332e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.408e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.429e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.023e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.671e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.198e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.048e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+03, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.990e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.552e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.747e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.510e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.579e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.378e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.844e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.576e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+03, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.067e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.660e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.129e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.256e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.663e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'elasticnet__alpha': 1, 'polynomialfeatures__degree': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "grid_1 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), ElasticNet(alpha=1, random_state=seed)),\n",
        "                    param_grid={'polynomialfeatures__degree': [1, 2, 3, 4],\n",
        "                    'elasticnet__alpha': [0.01, 0.1, 1, 10]},\n",
        "                    cv=kfold,\n",
        "                    refit=True)\n",
        "grid_1.fit(X, y)\n",
        "grid_1.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'alpha':[0.000000001, 0.0001, 0.1, 0.5, 1, 1.5, 2, 3, 4, 10]}\n",
        "lasso_model = Lasso()\n",
        "grid_2 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=1, random_state=seed)),\n",
        "                    param_grid={'polynomialfeatures__degree': [1, 1.5, 2, 2.5, 3, 4],\n",
        "                    'lasso__alpha': [0.01, 0.05, 0.1, 1, 1.5, 10]},\n",
        "                    cv=kfold,\n",
        "                    refit=True)\n",
        "grid_2.fit(X, y)\n",
        "print(grid_2.best_params_)\n"
      ],
      "metadata": {
        "id": "4Nlx75f7gKN_",
        "outputId": "0722d8c7-6e38-4f4f-bd8d-8ad33ea13afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.123e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.919e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.533e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.047e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.671e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.353e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.836e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.014e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.582e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.301e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.426e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.411e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.363e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.017e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.771e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.205e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.361e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.630e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.044e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.669e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.801e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.727e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.570e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.221e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.846e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.393e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.982e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+03, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.524e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.337e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.269e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.303e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.801e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.331e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.457e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.004e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.847e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.309e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+03, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.872e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.759e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.673e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.494e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.493e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.922e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.495e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.134e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.988e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.786e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+01, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+03, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+03, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+03, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+03, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.920e+02, tolerance: 3.828e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e+02, tolerance: 3.406e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.542e+02, tolerance: 2.666e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.941e+02, tolerance: 3.673e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lasso__alpha': 1, 'polynomialfeatures__degree': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.510e+02, tolerance: 2.539e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 180.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_polynomial.py\", line 314, in fit\n",
            "    \"degree must be a non-negative int or tuple \"\n",
            "ValueError: degree must be a non-negative int or tuple (min_degree, max_degree), got 1.5.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_polynomial.py\", line 314, in fit\n",
            "    \"degree must be a non-negative int or tuple \"\n",
            "ValueError: degree must be a non-negative int or tuple (min_degree, max_degree), got 2.5.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [ 9.15236069e-02             nan -1.61329435e+02             nan\n",
            " -7.05056746e+02 -6.66836740e+03  2.91486392e-01             nan\n",
            " -1.02876425e+00             nan -6.43530785e+02 -1.70331869e+05\n",
            "  3.90250074e-01             nan -4.99653930e-01             nan\n",
            " -8.80046576e+01 -5.34584852e+05  4.18909772e-01             nan\n",
            " -2.50016206e-01             nan -8.57322869e+01 -5.53833042e+03\n",
            "  3.65377872e-01             nan -2.35129079e-02             nan\n",
            " -2.57138273e+01 -5.89062337e+03  1.88516993e-01             nan\n",
            "  2.96984990e-01             nan -4.04638974e-01 -1.11030915e+03]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'alpha':[0.000000001, 0.0001, 0.1, 1, 2, 3, 4, 10]}\n",
        "ridge_model = Ridge()\n",
        "grid_3 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), Ridge(alpha=1, random_state=seed)),\n",
        "                    param_grid={'polynomialfeatures__degree': [1, 1.5, 2, 2.5, 3, 4],\n",
        "                    'ridge__alpha': [0.01, 0.05, 0.1, 0.15, 1, 10]},\n",
        "                    cv=kfold,\n",
        "                    refit=True)\n",
        "grid_3.fit(X, y)\n",
        "print(grid_3.best_params_)\n"
      ],
      "metadata": {
        "id": "WzVSlIe2gWIG",
        "outputId": "afca30bf-ce14-4383-f1d0-a81389e331d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:194: LinAlgWarning: Ill-conditioned matrix (rcond=3.47398e-20): result may not be accurate.\n",
            "  dual_coef = linalg.solve(K, y, sym_pos=True, overwrite_a=False)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'polynomialfeatures__degree': 1, 'ridge__alpha': 10}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:197: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  \"Singular matrix in solving dual problem. Using \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "60 fits failed out of a total of 180.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_polynomial.py\", line 314, in fit\n",
            "    \"degree must be a non-negative int or tuple \"\n",
            "ValueError: degree must be a non-negative int or tuple (min_degree, max_degree), got 1.5.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 355, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_polynomial.py\", line 314, in fit\n",
            "    \"degree must be a non-negative int or tuple \"\n",
            "ValueError: degree must be a non-negative int or tuple (min_degree, max_degree), got 2.5.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-1.94482324e-01 -1.70762122e-01 -1.44809917e-01 -1.22200303e-01\n",
            "  5.31957266e-02  2.72900855e-01             nan             nan\n",
            "             nan             nan             nan             nan\n",
            " -6.50046069e+02 -5.25624745e+02 -4.52307360e+02 -4.05249531e+02\n",
            " -1.48573093e+02 -8.46599177e+00             nan             nan\n",
            "             nan             nan             nan             nan\n",
            " -4.22646850e+05 -5.20758711e+05 -3.42811531e+05 -5.68417637e+05\n",
            " -5.32572673e+05 -2.32905041e+05 -9.97195123e+05 -9.97195123e+05\n",
            " -9.97195123e+05 -9.97195123e+05 -9.97195123e+05 -9.97195123e+05]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_model = linear_model.LinearRegression()\n",
        "grid_4 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), linear_model.LinearRegression()),\n",
        "                    param_grid={'polynomialfeatures__degree': [1, 2, 3, 4]},\n",
        "                    cv=kfold,\n",
        "                    refit=True)\n",
        "grid_4.fit(X, y)\n",
        "print(grid_4.best_params_)\n"
      ],
      "metadata": {
        "id": "0XmY9JJzgZme",
        "outputId": "7789ddcb-5ee4-4e6c-d51c-87f5538ea552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'polynomialfeatures__degree': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qExQbXUXfsvB",
        "outputId": "13c06254-9c87-40f6-9e9e-fb8e236477bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.56359058e-01, -1.81971026e+02, -1.25827594e+03,\n",
              "        -2.94601984e+04],\n",
              "       [ 4.14883696e-01, -9.67566969e-01, -5.57237890e+02,\n",
              "        -3.23763009e+05],\n",
              "       [ 4.70838951e-01,  1.12055989e-01, -8.87555304e+01,\n",
              "        -8.78702543e+03],\n",
              "       [ 2.14677917e-01,  1.92715153e-01, -9.81211483e-01,\n",
              "        -1.08972348e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "grid_1.cv_results_['mean_test_score'].reshape(4, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MrNJlHeofsvC",
        "outputId": "f35303eb-397b-4653-84d1-98cab8693833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.matshow(grid_1.cv_results_['mean_test_score'].reshape(4, -1),\n",
        "vmin=0, cmap=\"viridis\")\n",
        "plt.xlabel(\"elasticnet__alpha\")\n",
        "plt.ylabel(\"polynomialfeatures__degree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "7Opecl8ffsvD",
        "outputId": "03b134e4-9692-4b28-ed46-a56bf6fe963a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.matshow(grid_2.cv_results_['mean_test_score'].reshape(6, -1),\n",
        "vmin=0, cmap=\"viridis\")\n",
        "plt.xlabel(\"lasso__alpha\")\n",
        "plt.ylabel(\"polynomialfeatures__degree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "WjBGzRK4fsvE",
        "outputId": "ad8f9ee8-b7d0-4157-f4d9-80248bbaf4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.matshow(grid_3.cv_results_['mean_test_score'].reshape(6, -1),\n",
        "vmin=0, cmap=\"viridis\")\n",
        "plt.xlabel(\"ridge__alpha\")\n",
        "plt.ylabel(\"polynomialfeatures__degree\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3ETWyINFfsvE",
        "outputId": "db8d1e8a-1fb3-42bd-d4f1-05f50dbc21a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "R^2: 0.26209780598926524\n",
            "Explained variance score: 0.2625203248283122\n",
            "Median absolute error: 2.0372732498523387\n",
            "Mean squared error: 13.918975295405088\n",
            "Mean absolute errors: 2.7860251774001714\n",
            "Lasso\n",
            "R^2: 0.2945970264429165\n",
            "Explained variance score: 0.29469272114054046\n",
            "Median absolute error: 1.9355672663158607\n",
            "Mean squared error: 13.305945749909911\n",
            "Mean absolute errors: 2.7136637564664916\n",
            "Ridge\n",
            "R^2: 0.3254678775719496\n",
            "Explained variance score: 0.326705962414229\n",
            "Median absolute error: 2.14783802927208\n",
            "Mean squared error: 12.723631972148073\n",
            "Mean absolute errors: 2.741822079534182\n"
          ]
        }
      ],
      "source": [
        "from sklearn import  metrics\n",
        "\n",
        "X_test=boston_X_test\n",
        "y_test=boston_y_test\n",
        "\n",
        "models = []\n",
        "models.append(('ElasticNet', grid_1.best_estimator_))\n",
        "models.append(('Lasso', grid_2.best_estimator_))\n",
        "models.append(('Ridge', grid_3.best_estimator_))\n",
        "# models.append(('LR', grid_4.best_estimator_))\n",
        "\n",
        "r2 = []\n",
        "explained_variance_score = []\n",
        "median_absolute_error = []\n",
        "mean_squared_error = []\n",
        "mean_absolute_error = []\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    print(\"R^2: {}\".format(metrics.r2_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"Explained variance score: {}\".format( metrics.explained_variance_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"Median absolute error: {}\".format( metrics.median_absolute_error(y_test, model.predict(X_test)) ))\n",
        "    print(\"Mean squared error: {}\".format( metrics.mean_squared_error(y_test, model.predict(X_test)) ))\n",
        "    print(\"Mean absolute errors: {}\".format(metrics.mean_absolute_error(y_test, model.predict(X_test)) ))\n",
        "    r2.append(metrics.r2_score(y_test, model.predict(X_test)))\n",
        "    explained_variance_score.append(metrics.explained_variance_score(y_test, model.predict(X_test)))\n",
        "    median_absolute_error.append( metrics.median_absolute_error(y_test, model.predict(X_test)))\n",
        "    mean_squared_error.append(metrics.mean_squared_error(y_test, model.predict(X_test)))\n",
        "    mean_absolute_error.append(metrics.mean_absolute_error(y_test, model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "I0Gpn4cIfsvF",
        "outputId": "c40f65d5-7d7e-4ddc-9d27-cc69ba29d7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Method        r2  explained_variance_score  median_absolute_error  \\\n",
              "0  Elastic  0.262098                  0.262520               2.037273   \n",
              "1    Lasso  0.294597                  0.294693               1.935567   \n",
              "2    Ridge  0.325468                  0.326706               2.147838   \n",
              "\n",
              "   mean_squared_error  mean_absolute_error  \n",
              "0           13.918975             2.786025  \n",
              "1           13.305946             2.713664  \n",
              "2           12.723632             2.741822  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da41d81d-6518-4fd7-83cb-f2303ec576b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>r2</th>\n",
              "      <th>explained_variance_score</th>\n",
              "      <th>median_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elastic</td>\n",
              "      <td>0.262098</td>\n",
              "      <td>0.262520</td>\n",
              "      <td>2.037273</td>\n",
              "      <td>13.918975</td>\n",
              "      <td>2.786025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lasso</td>\n",
              "      <td>0.294597</td>\n",
              "      <td>0.294693</td>\n",
              "      <td>1.935567</td>\n",
              "      <td>13.305946</td>\n",
              "      <td>2.713664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge</td>\n",
              "      <td>0.325468</td>\n",
              "      <td>0.326706</td>\n",
              "      <td>2.147838</td>\n",
              "      <td>12.723632</td>\n",
              "      <td>2.741822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da41d81d-6518-4fd7-83cb-f2303ec576b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da41d81d-6518-4fd7-83cb-f2303ec576b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da41d81d-6518-4fd7-83cb-f2303ec576b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import pandas as pd\n",
        "d = {'r2': r2, \n",
        "     'explained_variance_score': explained_variance_score, \n",
        "     'median_absolute_error': median_absolute_error,\n",
        "     'mean_squared_error' : mean_squared_error,\n",
        "     'mean_absolute_error' : mean_absolute_error,\n",
        "    }\n",
        "df = pd.DataFrame(data=d)\n",
        "df.insert(loc=0, column='Method', value=['Elastic', 'Lasso', 'Ridge'])#'ElasticNet',,'LR'])\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Z07_C_cross_validation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}